\documentclass[12pt]{article}
\usepackage{myart}\addbibresource{/Users/lwg342/Documents/LaTeX/lib.bib}
%--------Hello World--------%
%=====================================%
\begin{document}
    \title{Prediction with interval outcomes}

    \section{Simulation 2023-11-23}
    \red{Red items are parameters of simulation that can be changed.}

    We randomly generate \red{sample size \(n\)} observations of \((y,x)\), where \(x\) is \red{\(k\)-dimensional},
    \begin{equation*}
        y_{i} = 2 + x_{i}' \beta + \epsilon_{i}\qq{and} \epsilon_{i} \sim N(0,1).
    \end{equation*}
    Let's assume we observe not \(y_{i}\), but \(y^{l}_{i}\) and \(y_{i}^{u}\). In the simulation, it's generated by 
    \begin{align*}
        y_{i}^{l} &= \lfloor y_{i} \rfloor - a_{1} \\
        y_{i}^{u} &= \lceil y_{i} \rceil  + a_{2},
    \end{align*}
    where \red{\(a_{1},a_{2}\)} will control how uncertain we are about our observations of \(y\). Let all \(\beta\)'s be \(1\), and \(x_{i}\) either have \red{normal \(N(0,I_{k})\) or uniform distribution \(U(0,3.4)\)}. We follow Elie's suggestions and do the following:
    \begin{enumerate}
        \item Split the sample into training and testing sets. 
        \item Randomly (uniformly) pick \(y^{m}_{i}\) in \((y^{l}_{i}, y^{u}_{i})\), \(m = 1,\dots, \red{M}\), and use them as the training set. Fit \(M\) linear regression models \(f_{m}\). Let \(\tilde{Y}(x) = \Bqty{f_{m}(x): m\in [M]}\) be the pre-selection prediction sets for a given evaluation point \(x\).
        \item Compute the score \(S_{m}\) for each model on the testing set, find the  minimum \(S_{m}^{*}\) and \(\mathcal{M}^{*} = \Bqty{m: S_{m} \leq S_{m}^{*} + \tau}\), where \red{\(\tau\)} is chosen to be \red{\(\frac{1}{n}\), or \(\frac{1}{\sqrt{n}}\)}. And the post-selection prediction sets are \(\hat{Y}(x) = \Bqty{f_{m}(x): m\in \mathcal{M}^{*}}\).
    \end{enumerate}
    
    Findings:
    \begin{enumerate}
        \item As we suspected, even if \(y\) is not uniformly distributed on \((y^{l},y^{u})\), it's okay to use uniform draws. 
        
        \item The following Figure \ref{fig:1} is the plot of the signal and predictions.  The parameters are \(n = 20000\), \(k = 5\), \(M = 500\) and \(\tau = \frac{1}{n}\). \(a_{1} = a_{2} = 1\) and \(x \sim N(0,I_{k})\). 

        
        \item It seems that if \(a_{1},a_{2}\) are larger, \(\mathcal{M}^{*}\) will expand, reflecting less identification. If \(\tau\) gets smaller, \(\mathcal{M}\) will expand too. In particular, for \(a_{1} = a_{2} = 3\), and \(\tau = \frac{1}{\sqrt{n}}\), \(\mathcal{M}^{*} = [M]\). 
        \item If sample size \(n\) is smaller, when \(n = 200\) and \(a_{1} = a_{2} = 1.0\), we have Figure \ref{fig:2}. Note that here \(x_{5}\) varies from \(0\) to \(3\), (compared to figure 1, the resolution is lower). 
    \end{enumerate}


        \begin{figure}[h]
            \centering
            \includegraphics[width = 0.8\textwidth]{test1-2023-11-23-20000-1.0.pdf}
            \caption{We fix \(x_{1} = \dots = x_{4} = 1\), while \(x_{5}\) takes value between \(1\) and \(1.5\). The reason to choose \((1,1.5)\) is to scale up the graph, so that we can see the difference between the signal and predictions.}
            \label{fig:1}
        \end{figure}
        \begin{figure}
            \centering
            \includegraphics[width = 0.8\textwidth]{test1-2023-11-23-200-1.0.pdf}
            \caption{We fix \(x_{1} = \dots = x_{4} = 1\), while \(x_{5}\) takes value between \(0\) and \(3\).}
            \label{fig:2}
        \end{figure}

% The End
% \printbibliography
\end{document}